{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1.Neural Networks(보스턴 집값 예측).ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMfvKF8p36yRqXpUjmATCcJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 본 코드는 \"딥러닝을 위한 파이토치 입문\" 책을 참고했습니다."],"metadata":{"id":"XKnl5oHEmP0M"}},{"cell_type":"markdown","source":["### 인공 신경망\n","\n","인공 신경망은 사람의 신경망을 모사하여 만든 예측 도구이다. 기본적으로 하나의 레이어에 다수의 노드를 가지고 있으며 여러 개의 레이어가 쌓인 신경망을\n","깊은 신경망이라고 한다. 이 때, 깊은 신경망을 이용하여 모델을 학습 시키는 방법을 딥러닝이라고 한다."],"metadata":{"id":"O4ibk596md3c"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"AYrxCn1Fmd5_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd # 데이터프레임 형태를 다룰 수 있는 라이브러리\n","import numpy as np\n","from sklearn.model_selection import train_test_split # 전체 데이터를 학습 데이터와 평가 데이터로 나눈다.\n","\n","# ANN\n","import torch\n","from torch import nn, optim # torch 내의 세부적인 기능을 불러온다. (신경망 기술, 손실함수, 최적화 방법 등)\n","from torch.utils.data import DataLoader, Dataset # 데이터를 모델에 사용할 수 있도록 정리해 주는 라이브러리\n","import torch.nn.functional as F # torch 내의 세부적인 기능을 불러온다. (신경망 기술 등)\n","\n","# Loss\n","from sklearn.metrics import mean_squared_error # Regression 문제의 평가를 위해 MSE(Mean Squared Error)를 불러온다.\n","\n","# Plot\n","import matplotlib.pyplot as plt # 시각화 도구"],"metadata":{"id":"t8v02r-fmd8r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4.1 데이터 불러오기"],"metadata":{"id":"WrDzhbTrmd_I"}},{"cell_type":"code","source":["PATH = '/content/drive/MyDrive/Pytorch Basic/deeplearningbro/pytorch/data/reg.csv'"],"metadata":{"id":"xsfcQVVPnX-Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv(PATH, index_col=[0])"],"metadata":{"id":"1W9EPzz1meDz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터프레임 보여주기\n","# df.head()는 상위 5줄만 보여준다.\n","# df.head(10) 괄호 안에 숫자 10을 넣으면 10줄을 보여준다. \n","df.head(5) "],"metadata":{"id":"XePTqEyhmeGG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(df)"],"metadata":{"id":"hVZTbG2wmeIf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4.2 데이터 변수와 타겟값 나누기"],"metadata":{"id":"ZZqzM4jtmeLA"}},{"cell_type":"code","source":["# 데이터를 넘파이 배열로 만들기\n","X = df.drop('Price', axis=1).to_numpy() # 데이터프레임에서 타겟값(Price)을 제외하고 넘파이 배열로 만들기\n","Y = df['Price'].to_numpy().reshape((-1,1)) # 데이터프레임 형태의 타겟값을 넘파이 배열로 만들기"],"metadata":{"id":"NpyQg4BymeNj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(X.shape)\n","print(Y.shape)"],"metadata":{"id":"Z6uwf6FOmeP1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4.3 텐서 데이터와 배치 만들기"],"metadata":{"id":"QxfgfbOPmeSU"}},{"cell_type":"code","source":["# 텐서 데이터로 변환하는 클래스(3강 참고)\n","class TensorData(Dataset):\n","\n","    def __init__(self, x_data, y_data):\n","        self.x_data = torch.FloatTensor(x_data)\n","        self.y_data = torch.FloatTensor(y_data)\n","        self.len = self.y_data.shape[0]\n","\n","    def __getitem__(self, index):\n","\n","        return self.x_data[index], self.y_data[index] \n","\n","    def __len__(self):\n","        return self.len"],"metadata":{"id":"HNtpqaDCmeUp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 전체 데이터를 학습 데이터와 평가 데이터로 나눈다.\n","# test size를 0.5로 설정한다.\n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.5)"],"metadata":{"id":"-EGAlCdhmeW8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 13개의 변수를 가지고 있는 X 데이터\n","X_train[:2]"],"metadata":{"id":"XH9t-uzdmeZG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 실제 예측을 해야하는 집값을 의미하는 Y 데이터 1개의 데이터\n","Y_train[:2]"],"metadata":{"id":"xGhxADqtm36H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 학습 데이터, 시험 데이터 배치 형태로 구축하기\n","trainsets = TensorData(X_train, Y_train)"],"metadata":{"id":"dyfSltA5m38x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(trainsets)\n","type(trainsets)"],"metadata":{"id":"kudEfES5m3_r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 미니 배치 32로, 하나의 미니배치는 32개의 데이터로 구성, 랜덤으로 셔플 on\n","trainloader = torch.utils.data.DataLoader(trainsets, batch_size=32, shuffle=True)"],"metadata":{"id":"MptuUyiUm4CQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(trainloader)\n","print(type(trainsets))"],"metadata":{"id":"F_O2RlFEm4Ef"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["testsets = TensorData(X_test, Y_test)\n","testloader = torch.utils.data.DataLoader(testsets, batch_size=32, shuffle=False)"],"metadata":{"id":"gHvAOmsmm4G9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["type(X_test)"],"metadata":{"id":"S1wraKjTm4Jj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(trainloader))\n","print(len(testloader))"],"metadata":{"id":"235anbkLm4ML"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4.4 모델 구축\n","\n","모델은 Regressor로 정의하며 입력층(노드 13개), 2개의 은닉층(50, 30개), 출력층(1개)으로 구성한다. 데이터의 변수는 13개이므로 입력층의 노드는\n","13개가 되고 출력층은 집 값인 단일 값을 추출하는 것이므로 1개가 된다. 은닉층에 대해서는 실험을 하면서 튜닝할 수 있다."],"metadata":{"id":"M9AW_H1Jm4Oy"}},{"cell_type":"code","source":["class Regressor(nn.Module):\n","    def __init__(self):\n","        super().__init__() # 모델 연산 정의\n","        self.fc1 = nn.Linear(13, 50, bias=True) # 입력층(13) -> 은닉층1(50)으로 가는 연산\n","        self.fc2 = nn.Linear(50, 30, bias=True) # 은닉층1(50) -> 은닉층2(30)으로 가는 연산\n","        self.fc3 = nn.Linear(30, 1, bias=True) # 은닉층2(30) -> 출력층(1)으로 가는 연산\n","        self.dropout = nn.Dropout(0.2) # 연산이 될 때마다 20%의 비율로 랜덤하게 노드를 없앤다.\n","\n","    def forward(self, x): # 모델 연산의 순서를 정의\n","        x = F.relu(self.fc1(x)) # Linear 계산 후 활성화 함수 ReLU를 적용한다.  \n","        x = self.dropout(F.relu(self.fc2(x))) # 은닉층2에서 드랍아웃을 적용한다.(즉, 30개의 20%인 6개의 노드가 계산에서 제외된다.)\n","        x = F.relu(self.fc3(x)) # Linear 계산 후 활성화 함수 ReLU를 적용한다.  \n","      \n","        return x\n","\n","# 집값의 경우 -가 없는 값이기 때문에 relu를 사용했다.    \n","# 주의 사항\n","# 드랍아웃은 과적합(overfitting)을 방지하기 위해 노드의 일부를 배제하고 계산하는 방식이기 때문에 절대로 출력층에 사용해서는 안 된다."],"metadata":{"id":"eSk7mAPIm4RU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4.5 모델, 손실함수, 최적화 방법 선언"],"metadata":{"id":"N2BRlxGqm4T8"}},{"cell_type":"code","source":["model = Regressor()\n","criterion = nn.MSELoss()\n","\n","# lr은 학습률이다.\n","# weight_decay는 L2 정규화에서의 penalty 정도를 의미한다.\n","optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-7)"],"metadata":{"id":"QNUf6-k6m4W0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4.6 학습 진행"],"metadata":{"id":"z0CSqiUnm4Zr"}},{"cell_type":"code","source":["loss_ = [] # 그래프를 그리기 위한 loss 저장용 리스트 \n","n = len(trainloader)\n","\n","for epoch in range(400): # 400번 학습을 진행한다.\n","\n","    running_loss = 0.0\n","    \n","    for i, data in enumerate(trainloader, 0): # 무작위로 섞인 32개 데이터가 있는 배치가 하나 씩 들어온다.\n","\n","        inputs, values = data # data에는 X, Y가 들어있다.\n","\n","        optimizer.zero_grad() # 최적화 초기화\n","        \n","        outputs = model(inputs) # 모델에 입력값 대입 후 예측값 산출\n","        loss = criterion(outputs, values) # 손실 함수 계산\n","        loss.backward() # 손실 함수 기준으로 역전파 설정 \n","        optimizer.step() # 역전파를 진행하고 가중치 업데이트\n","        \n","        running_loss += loss.item() # epoch 마다 평균 loss를 계산하기 위해 배치 loss를 더한다.\n"," \n","\n","    loss_.append(running_loss/n) # MSE(Mean Squared Error) 계산\n","\n","        \n","print('Finished Training')"],"metadata":{"id":"VbPgkMMym4cF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(loss_)\n","plt.title(\"Training Loss\")\n","plt.xlabel(\"epoch\")\n","plt.show()"],"metadata":{"id":"TbLVP_X9m4e7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4.7 모델 평가"],"metadata":{"id":"Tf1k0Jl7m4hk"}},{"cell_type":"code","source":["def evaluation(dataloader):\n","    \n","    predictions = torch.tensor([], dtype=torch.float) # 예측값을 저장하는 텐서\n","    actual = torch.tensor([], dtype=torch.float) # 실제값을 저장하는 텐서\n","        \n","    with torch.no_grad():\n","        model.eval() # 평가를 할 때에는 .eval() 반드시 사용해야 한다. dropout의 적용을 없애준다.\n","        for data in dataloader:\n","            inputs, values = data\n","            outputs = model(inputs)\n","\n","            predictions = torch.cat((predictions, outputs), 0) # cat을 통해 예측값을 누적 마지막 0은 행 기준으로 하나씩 쌓겠다는뜻\n","            actual = torch.cat((actual, values), 0) # cat을 통해 실제값을 누적\n","    \n","    predictions = predictions.numpy() # 넘파이 배열로 변경\n","    actual = actual.numpy() # 넘파이 배열로 변경\n","    rmse = np.sqrt(mean_squared_error(predictions, actual)) # sklearn을 이용하여 RMSE 계산\n","    \n","    return rmse  \n","\n","# 평가 시 .eval()을 사용해야 하는 이유\n","# 평가 시에는 온전한 모델로 평가를 해야하는데 .eval()이 아닌 .train()인 경우 드랍아웃이 활성화 되어 있다.\n","# 따라서 드랍아웃이나 배치 정규화 등과 같이 학습 시에만 사용하는 기술들을 평가 시에는 비활성화 해야만 한다."],"metadata":{"id":"98uavIYqm4kE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_rmse = evaluation(trainloader) # 학습 데이터의 RMSE\n","test_rmse = evaluation(testloader) # 시험 데이터의 RMSE\n","\n","print(\"Train RMSE: \",train_rmse)\n","print(\"Test RMSE: \",test_rmse)\n","\n","# 예시를 위한 단순 비교입니다. 실제 연구에서는 디테일한 비교가 필요합니다.\n","# 20번의 평가 결과의 평균으로 결과값을 산정 했습니다.\n","# 데이터를 무작위로 나누고 모델의 초기값도 random initial parameter를 사용했기 때문에 학습을 할 때 마다 결과가 다르게 나올 수 있습니다.\n","# 이 강의에서는 학습의 흐름(for문)과 모델(Regressor) 부분을 주의 깊게 보시면 됩니다."],"metadata":{"id":"bIb11WwfnHh4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Git commit"],"metadata":{"id":"GHx9p50rnHkr"}},{"cell_type":"code","source":["cd/content/drive/MyDrive/Git_link/Deeplearning/pytorch_basic"],"metadata":{"id":"CdRIZwG4nHnP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git config --global user.email \"injaeda7@gmail.com\"\n","!git config --global user.name \"SEOINJAE\""],"metadata":{"id":"xxJEgR3enHpK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git pull"],"metadata":{"id":"NHKgtwNcno_v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git add ."],"metadata":{"id":"C2RK8x3rnHrE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git commit -m \"chapter 4 done\""],"metadata":{"id":"1MUcedlTnHtX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git push"],"metadata":{"id":"CqtIkILznHvU"},"execution_count":null,"outputs":[]}]}